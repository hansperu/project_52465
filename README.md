# project_52465
# Project Programming for Data Analysis

## Student: Hans Pérez Rubín de Celis

## Student ID number: G00387884

For this project you must create a data set by simulating a real-world phenomenon of
your choosing. You may pick any phenomenon you wish – you might pick one that is
of interest to you in your personal or professional life. Then, rather than collect data
related to the phenomenon, you should model and synthesise such data using Python.
We suggest you use the numpy.random package for this purpose.

Specifically, in this project you should:

• Choose a real-world phenomenon that can be measured and for which you could
collect at least one-hundred data points across at least four different variables.

• Investigate the types of variables involved, their likely distributions, and their
relationships with each other.

• Synthesise/simulate a data set as closely matching their properties as possible.

• Detail your research and implement the simulation in a Jupyter notebook – the
data set itself can simply be displayed in an output cell within the notebook.
Note that this project is about simulation – you must synthesise a data set. Some
students may already have some real-world data sets in their own files. It is okay to
base your synthesised data set on these should you wish (please reference it if you do),
but the main task in this project is to create a synthesised data set. The next section
gives an example project idea.

## 1.- Project plan.
This project refers to a current problem that is to analyze health centers where a series of patients have been admitted as a result of the coronavirus. For this project we will use the Jupyter notebook.
## 2.- The problem to solve.
First, we will identify a series of variables that we have collected from a health.csv file. Once the variables have been identified, we will start reading the data. For later data preprocessing. As a third step we will develop the modeling. And as a last step the visualization of the results for analysis. As you can see it is hoped to break this project down into several smaller tasks that are easier to solve and connect once they are completed.
## 3.- Methodology to follow
The methodology for the development of this project is developed in 6 stages that make up a complete data analysis process.
a) Identify the problem.
b) Data collection.
c) The cleaning of the data.
d) Exploring the data.
e) Data analysis.
This project has been developed meeting the following objectives:
### 3.1. Research on the use of data to fight the coronavirus.
### 3.2. A series of data has been downloaded and our repository added.
### 3.3. Work begins on the project through a jupyter notebook:

## I. Process for programming for data analysis.

### Technology
* Anaconda
* Python 3.8.2
* Visual Studio code: March 2020 (version 1.44)
* Git 2.26.1
* Gihub
* GDB Online is an online compilation and debugging tool for Anaconda, Python, compile, run and debug online from anywhere in the world.
* Operating system: Ubuntu 19.10 - Windows 10 Pro - 64 bits

### Hardware requirements
- Number of cores: 4
- Release Date: Intel (R) Core (TM) i7-4790 CPU
- RAM 8.00 GB
- Clock frequency: 3.6 GHz
- CPU benchmark score: 1833

### Objective of the project.

The main objective of this project is to work with the data set of health centers where data has been taken from possible coronavirus infections, for this we will use a jupyter and Python notebook.

We will previously install [Anaconda](https://www.anaconda.com/products/individual) which is the most complete Suite for Data Science with Python.

## Introduction.
Currently the pandemic caused by covid 19 (coronavirus) has caused a high risk for all humanity, for this reason it is important to have information stored and prepared to help us fight the pandemic.
However, despite the fact that we have information in those developing countries such as South America, they have had to fight not only against the pandemic but also with access to information, access to health, access to better living conditions, to decision making.

Corruption in the middle of the pandemic has become more evident as is the case in Peru, Bolivia.
The article "Use data to accelerate your business strategy", published in Harvard Business Review, states "The management team of the center understood that a better use of data must become a fundamental health practice" for all this, governments are giving consider the benefits of having a data-driven decision-making culture such as:

#### 1. Identification of needs when implementing hospital facilities and thus contribute to reducing unnecessary expenses at the time of implementation.

#### 2. Optimization of processes, which contributes to the reduction of operational costs.

#### 3. Proactive monitoring to detect potential “unusual” situations and, in this way, avoid economic losses and identify improvements for the control environment.

#### 4. Identification of opportunities for automation, cloud computing, machine learning and predictive analytics that could contribute to the simulation of scenarios to fight the pandemic.

National and local governments must make their decisions based on data and with this they have the possibility of constantly identifying coronavirus cases and thus optimizing operations contributing to a better fight against the pandemic.
Another important aspect that has increased as a result of the pandemic has been remote work and the slowdown in the economy as a result of the COVID-19 pandemic. All this aspect has meant for the companies the flexibility of their controls, the pressure to optimize operating costs and the prevention of situations that could cause economic losses.
For all this, we have seen fit to work with a current problem. We have collected information from 30 health centers in Lima.

## Bibliographic references

#### [Python Machine Learning - Second Edition](http://search.ebscohost.com/login.aspx?direct=true&AuthType=ip,sso&db=nlebk&AN=1606531&site=eds-live&scope=site&custid=s2873033&ebv=EB&ppid=pp_9)
Author:Raschka, Sebastian, Mirjalili, Vahid

![book1](https://user-images.githubusercontent.com/60121637/82153453-66aab500-985f-11ea-881a-fd5e2bbd3c8e.png)

#### [Mastering Social Media Mining with Python](http://search.ebscohost.com/login.aspx?direct=true&AuthType=ip,sso&db=e000xww&AN=1295360&site=eds-live&scope=site&custid=s2873033&ebv=EB&ppid=pp_32)
Author: Bonzanini, Marco

![book2](https://user-images.githubusercontent.com/60121637/82153488-a40f4280-985f-11ea-9b14-a7f0f4cf5d67.png)
#### [Python Data Science Essentials - Second Edition](http://search.ebscohost.com/login.aspx?direct=true&AuthType=ip,sso&db=e000xww&AN=1409191&site=eds-live&scope=site&custid=s2873033&ebv=EB&ppid=pp_Cover)
Author: Boschetti, Alberto, Massaron, Luca

![book3](https://user-images.githubusercontent.com/60121637/82153641-a756fe00-9860-11ea-8245-e15e478f1450.png)

